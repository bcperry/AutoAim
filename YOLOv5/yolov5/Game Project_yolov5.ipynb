{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46bd678d-cb7c-4419-8e26-e9c6e5b9236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import pyautogui\n",
    "import time\n",
    "import win32api, win32con\n",
    "from utils.torch_utils import select_device\n",
    "from utils.general import non_max_suppression\n",
    "from utils.augmentations import letterbox\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "DEVICE = 'cuda'\n",
    "LOAD_MODEL_FILE = \"Halo640.pt\"\n",
    "image_size = 640\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-4-17 torch 1.11.0 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7012822 parameters, 0 gradients\n"
     ]
    },
    {
     "data": {
      "text/plain": "DetectMultiBackend(\n  (model): Model(\n    (model): Sequential(\n      (0): Conv(\n        (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n        (act): SiLU(inplace=True)\n      )\n      (1): Conv(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (2): C3(\n        (cv1): Conv(\n          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv3): Conv(\n          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): Sequential(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (3): Conv(\n        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (4): C3(\n        (cv1): Conv(\n          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv3): Conv(\n          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): Sequential(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n          (1): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (5): Conv(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (6): C3(\n        (cv1): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv3): Conv(\n          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): Sequential(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n          (1): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n          (2): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (7): Conv(\n        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (8): C3(\n        (cv1): Conv(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv3): Conv(\n          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): Sequential(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (9): SPPF(\n        (cv1): Conv(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n      )\n      (10): Conv(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (11): Upsample(scale_factor=2.0, mode=nearest)\n      (12): Concat()\n      (13): C3(\n        (cv1): Conv(\n          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv3): Conv(\n          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): Sequential(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (14): Conv(\n        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (15): Upsample(scale_factor=2.0, mode=nearest)\n      (16): Concat()\n      (17): C3(\n        (cv1): Conv(\n          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv3): Conv(\n          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): Sequential(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (18): Conv(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (19): Concat()\n      (20): C3(\n        (cv1): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv3): Conv(\n          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): Sequential(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (21): Conv(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n        (act): SiLU(inplace=True)\n      )\n      (22): Concat()\n      (23): C3(\n        (cv1): Conv(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (cv3): Conv(\n          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (m): Sequential(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (24): Detect(\n        (m): ModuleList(\n          (0): Conv2d(128, 18, kernel_size=(1, 1), stride=(1, 1))\n          (1): Conv2d(256, 18, kernel_size=(1, 1), stride=(1, 1))\n          (2): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHECKPOINT_NAME = LOAD_MODEL_FILE\n",
    "checkpoint = torch.load(CHECKPOINT_NAME)\n",
    "\n",
    "device = select_device('')\n",
    "\n",
    "model = DetectMultiBackend(CHECKPOINT_NAME, device=device, dnn=False, data='Halodata.yaml', fp16=False)\n",
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "\n",
    "model.eval()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# function to convert a torchtensor back to PIL image\n",
    "def torch_to_pil(img):\n",
    "    return torchvision.transforms.ToPILImage()(img).convert('RGB')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "show = True\n",
    "dbg = True\n",
    "\n",
    "#centering is how much of the screen to account for, from the center\n",
    "centering = 1 # how much of the screen to grab\n",
    "\n",
    "threshold = .5\n",
    "sct = mss()\n",
    "\n",
    "movement_scale = 8\n",
    "\n",
    "w, h = pyautogui.size()\n",
    "\n",
    "x_center = w/2\n",
    "y_center = h/2\n",
    "\n",
    "top = int(y_center - (y_center * centering))\n",
    "left = int(x_center - (x_center * centering))\n",
    "bottom = int(y_center + (y_center * centering))\n",
    "right = int(x_center + (x_center * centering))\n",
    "\n",
    "width = int(w * centering)\n",
    "height = int(h * centering)\n",
    "monitor = {'top': top, 'left': left, 'width': width, 'height': height}\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "while True:\n",
    "    if dbg:\n",
    "        start = time.time()\n",
    "\n",
    "    orig_img = sct.grab(monitor)\n",
    "    img = np.array(Image.frombytes('RGB', (orig_img.size.width, orig_img.size.height), orig_img.rgb))\n",
    "\n",
    "    # Padded resize\n",
    "    img = letterbox(img, (image_size, image_size), stride=stride, auto=pt)[0]\n",
    "\n",
    "\n",
    "\n",
    "    # Convert\n",
    "    img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img = torch.from_numpy(img).to(device).float()\n",
    "\n",
    "    img /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction = model(img.unsqueeze(0))\n",
    "\n",
    "    pred = non_max_suppression(prediction)[0]\n",
    "\n",
    "    img = np.array(torch_to_pil(img))\n",
    "\n",
    "    if dbg:\n",
    "        framerate = 1/(time.time() - start)\n",
    "\n",
    "\n",
    "    #add framerate to the cv2 image\n",
    "    cv2.putText(img, str(framerate), (50, 50), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    if len(pred) > 0:\n",
    "        for box in pred:\n",
    "            if box[4] > threshold:\n",
    "                box_dim = (box[3] - box[1])  #also used to scale inputs later on\n",
    "                x = (box[2] + box[0]) / 2\n",
    "                y = ((box[3] + box[1]) / 2) - ((box[3] - box[1]) / 3)\n",
    "                cv2.circle(img,\n",
    "                    (int(x), int(y)),\n",
    "                    radius=10,\n",
    "                    color=(255, 0, 0),\n",
    "                    thickness=5\n",
    "                )\n",
    "\n",
    "                #get the coordinates in the full size space\n",
    "                x = x / img.shape[1] * orig_img.size[0]\n",
    "\n",
    "                y = y / img.shape[0] * orig_img.size[1]\n",
    "\n",
    "                win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, int(movement_scale*box_dim/orig_img.size.height*(x.item()-x_center)), int(movement_scale*box_dim/orig_img.size.height*(y.item()-y_center)))\n",
    "\n",
    "    if show:\n",
    "        #img = cv2.resize(img, (orig_img.size.width, orig_img.size.height))\n",
    "        cv2.imshow('test', np.array(img))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        print(framerate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# # to view test images\n",
    "#\n",
    "# import glob\n",
    "# # for img in glob.glob('C:/Users/blain/Documents\\Git\\AutoAim\\model\\halo_data/*.png'):\n",
    "# for img in glob.glob('C:/Users/blain\\Documents\\Git\\AutoAim\\model\\halo_data/new/*'):\n",
    "#\n",
    "#     img = Image.open(img)\n",
    "#     img = img.resize(resize)\n",
    "#     img_transform = transform(img).unsqueeze(0).cuda()\n",
    "#     img = np.array(img)\n",
    "#\n",
    "#\n",
    "#     boxes = utils.cellboxes_to_boxes(model(img_transform))\n",
    "#     boxes = utils.non_max_suppression(boxes[0], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n",
    "#     primary, secondary = utils.pick_targets(img, boxes)\n",
    "#\n",
    "#     # add aim points to image\n",
    "#     for aimpoint in primary:\n",
    "#         print(aimpoint)\n",
    "#         cv2.circle(img,\n",
    "#             (int(aimpoint[0]), int(aimpoint[1])),\n",
    "#             radius=10,\n",
    "#             color=(255, 0, 0),\n",
    "#             thickness=5\n",
    "#         )\n",
    "#     cv2.imshow('test', cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR))\n",
    "#\n",
    "#     if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "#\n",
    "#         break\n",
    "# cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "autoaim",
   "language": "python",
   "display_name": "autoaim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}