{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46bd678d-cb7c-4419-8e26-e9c6e5b9236d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-4-17 torch 1.11.0 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the relevant libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import ctypes\n",
    "import time\n",
    "import win32api, win32con\n",
    "from utils.torch_utils import select_device\n",
    "from utils.general import non_max_suppression\n",
    "from utils.augmentations import letterbox\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "\n",
    "#User parameters\n",
    "show = True # boolean if the user wants to see the model output\n",
    "control = False # boolean if the user wants the model to control the input device\n",
    "\n",
    "DEVICE = select_device('') # a method which returns gpu availability, provided by YOLOv5\n",
    "LOAD_MODEL_FILE = \"Halo640v2.pt\" # the saved model file name\n",
    "image_size = 1280 # size of the output screen\n",
    "auto_screen = False # boolean should the program find the screen size automatically\n",
    "\n",
    "\n",
    "centering = 1 #centering is the decimal percentage of the screen to account for, from the center, from 0 to 1\n",
    "\n",
    "threshold = .8 # threshold is the lowest confidence bound to be allowed to be considered a detection\n",
    "\n",
    "movement_scale =  640/image_size # a scaling factor based on the image size, required for proper mouse control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\blain/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-4-17 torch 1.11.0 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7012822 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": "AutoShape(\n  (model): DetectMultiBackend(\n    (model): Model(\n      (model): Sequential(\n        (0): Conv(\n          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n          (act): SiLU(inplace=True)\n        )\n        (1): Conv(\n          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (2): C3(\n          (cv1): Conv(\n            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv3): Conv(\n            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n        (3): Conv(\n          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (4): C3(\n          (cv1): Conv(\n            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv3): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n            (1): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n        (5): Conv(\n          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (6): C3(\n          (cv1): Conv(\n            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv3): Conv(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n            (1): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n            (2): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n        (7): Conv(\n          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (8): C3(\n          (cv1): Conv(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv3): Conv(\n            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n        (9): SPPF(\n          (cv1): Conv(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n        )\n        (10): Conv(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (11): Upsample(scale_factor=2.0, mode=nearest)\n        (12): Concat()\n        (13): C3(\n          (cv1): Conv(\n            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv3): Conv(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n        (14): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (15): Upsample(scale_factor=2.0, mode=nearest)\n        (16): Concat()\n        (17): C3(\n          (cv1): Conv(\n            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv3): Conv(\n            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n        (18): Conv(\n          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (19): Concat()\n        (20): C3(\n          (cv1): Conv(\n            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv3): Conv(\n            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n        (21): Conv(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n          (act): SiLU(inplace=True)\n        )\n        (22): Concat()\n        (23): C3(\n          (cv1): Conv(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv2): Conv(\n            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (cv3): Conv(\n            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n            (act): SiLU(inplace=True)\n          )\n          (m): Sequential(\n            (0): Bottleneck(\n              (cv1): Conv(\n                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n              (cv2): Conv(\n                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n                (act): SiLU(inplace=True)\n              )\n            )\n          )\n        )\n        (24): Detect(\n          (m): ModuleList(\n            (0): Conv2d(128, 18, kernel_size=(1, 1), stride=(1, 1))\n            (1): Conv2d(256, 18, kernel_size=(1, 1), stride=(1, 1))\n            (2): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n          )\n        )\n      )\n    )\n  )\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=LOAD_MODEL_FILE) # load the model trained on our Halo dataset\n",
    "model.eval() # set the model to evaluation mode"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# if the user wants to\n",
    "if auto_screen:\n",
    "    w, h = ctypes.windll.user32.GetSystemMetrics(0), ctypes.windll.user32.GetSystemMetrics(1)\n",
    "else:\n",
    "    w, h = 1280,807 # if the user wants to define the screen size, do so here\n",
    "\n",
    "# find the center point of the screen\n",
    "x_center = w/2\n",
    "y_center = h/2\n",
    "\n",
    "# because we want to be able to take screencaptures that do not use the entire screen, we need to define the top, bottom, left, and right bounds of the box in pixels\n",
    "top = int(y_center - (y_center * centering))\n",
    "left = int(x_center - (x_center * centering))\n",
    "bottom = int(y_center + (y_center * centering))\n",
    "right = int(x_center + (x_center * centering))\n",
    "\n",
    "width = int(w * centering)\n",
    "height = int(h * centering)\n",
    "\n",
    "# we save these as a dictionary to be used with\n",
    "monitor = {'top': top, 'left': left, 'width': width, 'height': height}\n",
    "\n",
    "sct = mss() #instantiate the screenshot application"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "\n",
    "# Begin the loop of screen inference\n",
    "while True:\n",
    "    start = time.time() # begin a timer to calculate framerate\n",
    "\n",
    "    orig_img = sct.grab(monitor) # capture the image from the screen defined in the monitor dict\n",
    "    img = Image.frombytes('RGB', (orig_img.size.width, orig_img.size.height), orig_img.rgb) # perform several conversions to prepare the image for the model\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img).pred # perform inference of the image.  The\n",
    "\n",
    "    img = np.array(img.convert('RGB')) # convert the image back to the correct color space and\n",
    "\n",
    "    framerate = 1/(time.time() - start) # stop the timer and calculate the framerate\n",
    "\n",
    "    cv2.putText(img, str(framerate), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA) #add framerate to the cv2 image\n",
    "\n",
    "    if len(pred) > 0: # if there were any predicted targets\n",
    "        closest = 99999 # set an arbitrarily large value for distance to the center\n",
    "        for box in pred[0]: # loop through all predicted targets\n",
    "            if box[4] > threshold: # if the prediction is above the user set confidence threshold\n",
    "                box_dim = (box[3] - box[1])  #Caclulate the box dimension to be used to scale inputs later on\n",
    "                x = (box[2] + box[0]) / 2 # find the x pixel value for the target\n",
    "                y = ((box[3] + box[1]) / 2) - ((box[3] - box[1]) / 3) # find the y pixel value for the target (scale up by 1/3 to aim for headshots)\n",
    "\n",
    "                # add the target to the image\n",
    "                cv2.circle(img,\n",
    "                    (int(x), int(y)),\n",
    "                    radius=10,\n",
    "                    color=(255, 0, 0),\n",
    "                    thickness=5\n",
    "                )\n",
    "\n",
    "                #get the coordinates in the full size space\n",
    "                x = x / img.shape[1] * orig_img.size[0]\n",
    "                y = y / img.shape[0] * orig_img.size[1]\n",
    "\n",
    "                dist_x = x.item()-x_center\n",
    "                dist_y = y.item()-y_center\n",
    "                dist = (dist_x**2 + dist_y**2)**(.5)\n",
    "                if dist < closest:\n",
    "                    closest = dist\n",
    "                    dx = dist_x\n",
    "                    dy = dist_y\n",
    "                    best_scale = box_dim/orig_img.size.height\n",
    "\n",
    "\n",
    "        if control and closest < 99999:\n",
    "            win32api.mouse_event(win32con.MOUSEEVENTF_MOVE,\n",
    "                                 int(.5*framerate* movement_scale*best_scale*dx),\n",
    "                                 int(.5*framerate* movement_scale*best_scale*dy),\n",
    "                                 )\n",
    "\n",
    "    if show:\n",
    "        cv2.imshow('Model View', np.array(img)[:,:,[2,1,0]])\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        print(framerate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "autoaim",
   "language": "python",
   "display_name": "autoaim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}