{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "472812d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.cudnn.enabled)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5bd855a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46bd678d-cb7c-4419-8e26-e9c6e5b9236d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-10-2 torch 1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import the relevant libraries\n",
    "import numpy as np\n",
    "import yaml\n",
    "import cv2\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import ctypes\n",
    "import time\n",
    "import win32con\n",
    "from utils.torch_utils import select_device\n",
    "from utils.general import non_max_suppression\n",
    "from utils.augmentations import letterbox\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "\n",
    "#User parameters\n",
    "show = True # boolean if the user wants to see the model output\n",
    "control = False # boolean if the user wants the model to control the input device\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = select_device('') # a method which returns gpu availability, provided by YOLOv5\n",
    "\n",
    "#LOAD_MODEL_FILE = \"Halo640v2.pt\" # the saved model file name\n",
    "image_size = 1280 # size of the output screen\n",
    "auto_screen = False # boolean should the program find the screen size automatically\n",
    "\n",
    "\n",
    "centering = 1 #centering is the decimal percentage of the screen to account for, from the center, from 0 to 1\n",
    "\n",
    "threshold = .8 # threshold is the lowest confidence bound to be allowed to be considered a detection\n",
    "\n",
    "movement_scale =  640/image_size # a scaling factor based on the image size, required for proper mouse control.\n",
    "\n",
    "with open('data/coco128.yaml', 'r', encoding=\"utf-8\") as file:\n",
    "    setup = yaml.safe_load(file)\n",
    "\n",
    "#get the list of class names\n",
    "class_list = setup['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9589a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\blain/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-10-2 torch 1.11.0+cu113 CUDA:0 (NVIDIA GeForce RTX 3070 Laptop GPU, 8192MiB)\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\blain\\Documents\\Git\\AutoAim\\YOLOv5\\yolov5\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoShape(\n",
       "  (model): DetectMultiBackend(\n",
       "    (model): Model(\n",
       "      (model): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Conv(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (4): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (6): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Conv(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (8): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): SPPF(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (10): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (11): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (12): Concat()\n",
       "        (13): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (15): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (16): Concat()\n",
       "        (17): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (19): Concat()\n",
       "        (20): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (21): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (22): Concat()\n",
       "        (23): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (24): Detect(\n",
       "          (m): ModuleList(\n",
       "            (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = torch.hub.load('ultralytics/yolov5', 'custom', path=LOAD_MODEL_FILE) # load the model trained on our Halo dataset\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "model.eval() # set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac21a95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the user wants to\n",
    "if auto_screen:\n",
    "    w, h = ctypes.windll.user32.GetSystemMetrics(0), ctypes.windll.user32.GetSystemMetrics(1)\n",
    "else:\n",
    "    w, h = 1280,807 # if the user wants to define the screen size, do so here\n",
    "\n",
    "# find the center point of the screen\n",
    "x_center = w/2\n",
    "y_center = h/2\n",
    "\n",
    "# because we want to be able to take screen captures that do not use the entire screen, we need to define the top, bottom, left, and right bounds of the box in pixels\n",
    "top = int(y_center - (y_center * centering))\n",
    "left = int(x_center - (x_center * centering))\n",
    "bottom = int(y_center + (y_center * centering))\n",
    "right = int(x_center + (x_center * centering))\n",
    "\n",
    "width = int(w * centering)\n",
    "height = int(h * centering)\n",
    "\n",
    "# we save these as a dictionary to be used with\n",
    "monitor = {'top': top, 'left': left, 'width': width, 'height': height}\n",
    "\n",
    "sct = mss() #instantiate the screenshot application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6f04b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.30863e+02, 4.76986e+02, 2.77494e+02, 8.07000e+02, 9.26919e-01, 0.00000e+00],\n",
      "        [3.00258e+02, 4.82095e+02, 4.20447e+02, 8.02014e+02, 8.79163e-01, 0.00000e+00],\n",
      "        [1.03029e+02, 3.08934e+02, 5.48144e+02, 8.00466e+02, 6.34115e-01, 5.00000e+00],\n",
      "        [6.20172e+02, 6.65836e+02, 1.27924e+03, 8.07000e+02, 3.42174e-01, 7.00000e+00],\n",
      "        [6.30769e+02, 6.63725e+02, 1.24961e+03, 8.07000e+02, 3.02772e-01, 5.00000e+00],\n",
      "        [8.10389e+02, 7.45611e+02, 8.93487e+02, 8.07000e+02, 2.70259e-01, 0.00000e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "orig_img = sct.grab(monitor) # capture the image from the screen defined in the monitor dict\n",
    "img = Image.frombytes('RGB', (orig_img.size.width, orig_img.size.height), orig_img.rgb) # perform several conversions to prepare the image for the model\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(img, size = 640).pred\n",
    "print(pred[0])\n",
    "\n",
    "img= np.array(img.convert('RGB'))\n",
    "\n",
    "for box in pred[0]:\n",
    "    class_num = int(box[5])\n",
    "    cv2.rectangle(img,\n",
    "                (int(box[0]), int(box[1])),\n",
    "                (int(box[2]), int(box[3])),\n",
    "                color=(0, 255, 0),\n",
    "                thickness=2,\n",
    "                )\n",
    "    cv2.putText(img,\n",
    "                org=(int(box[0]), int(box[1])), \n",
    "                text=str(class_list[class_num]), \n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                fontScale=1, \n",
    "                color=(255,0,0),\n",
    "                thickness=2\n",
    "                )\n",
    "\n",
    "        \n",
    "cv2.imshow('Model View', np.array(img)[:,:,[2,1,0]])\n",
    "if cv2.waitKey(1) & 0xff ==ord('q'): # The wait insures the image is shown, and the other portion of the command allows the user to stop the program by pressing 'q'\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c41c9353",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Begin the loop of screen inference\n",
    "while True:\n",
    "    start = time.time() # begin a timer to calculate framerate\n",
    "\n",
    "    orig_img = sct.grab(monitor) # capture the image from the screen defined in the monitor dict\n",
    "    img = Image.frombytes('RGB', (orig_img.size.width, orig_img.size.height), orig_img.rgb) # perform several conversions to prepare the image for the model\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img, size = 640).pred # perform inference of the image.  The\n",
    "\n",
    "    img = np.array(img.convert('RGB')) # convert the image back to the correct color space and\n",
    "\n",
    "    framerate = 1/(time.time() - start) # stop the timer and calculate the framerate\n",
    "\n",
    "    cv2.putText(img, str(framerate), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA) #add framerate to the cv2 image\n",
    "\n",
    "    if len(pred) > 0: # if there were any predicted targets\n",
    "        closest = 99999 # set an arbitrarily large value for distance to the center\n",
    "        for box in pred[0]: # loop through all predicted targets\n",
    "        \n",
    "\n",
    "            if box[4] > threshold: # if the prediction is above the user set confidence threshold\n",
    "                box_dim = (box[3] - box[1])  #Caclulate the box dimension to be used to scale inputs later on\n",
    "                x = (box[2] + box[0]) / 2 # find the x pixel value for the target\n",
    "                y = ((box[3] + box[1]) / 2) - ((box[3] - box[1]) / 3) # find the y pixel value for the target (scale up by 1/3 to aim for headshots)\n",
    "                class_num = int(box[5]) # find the class value for the target\n",
    "                # getting the xywh bounding box coordinates\n",
    "                # x, y, w, h = float(box[1]), float(box[2]), float(box[3]), float(box[4])\n",
    "                        \n",
    "                # add the target to the image\n",
    "                cv2.circle(img,\n",
    "                    (int(x), int(y)),\n",
    "                    radius=10,\n",
    "                    color=(255, 0, 0),\n",
    "                    thickness=5\n",
    "                )\n",
    "                cv2.rectangle(img,\n",
    "                            (int(box[0]), int(box[1])),\n",
    "                            (int(box[2]), int(box[3])),\n",
    "                            color=(0, 255, 0),\n",
    "                            thickness=2,\n",
    "                            )\n",
    "                cv2.putText(img,\n",
    "                            org=(int(box[0]), int(box[1])), \n",
    "                            text=str(class_list[class_num]), \n",
    "                            fontFace=cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            fontScale=1, \n",
    "                            color=(255,0,0),\n",
    "                            thickness=2\n",
    "                            )\n",
    "\n",
    "\n",
    "                #get the coordinates in the full size space\n",
    "                x = x / img.shape[1] * orig_img.size[0]\n",
    "                y = y / img.shape[0] * orig_img.size[1]\n",
    "\n",
    "                # Calculate the distance to the target\n",
    "                dist_x = x.item()-x_center\n",
    "                dist_y = y.item()-y_center\n",
    "                dist = (dist_x**2 + dist_y**2)**(.5)\n",
    "\n",
    "                # if this target is closer than the previous closest target, save its infromation as the closest target\n",
    "                if dist < closest:\n",
    "                    closest = dist\n",
    "                    dx = dist_x\n",
    "                    dy = dist_y\n",
    "                    best_scale = box_dim/orig_img.size.height\n",
    "\n",
    "        # if the user wants the program to control the mouse\n",
    "        if control and closest < 99999:\n",
    "            win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, # use the windows api to move the mouse\n",
    "                                 int(.5*framerate* movement_scale*best_scale*dx), # this is the x increment to move, note the modifiers used to account for target distnace and framerate\n",
    "                                 int(.5*framerate* movement_scale*best_scale*dy), # this is the y incrememnt to move, see above\n",
    "                                 )\n",
    "\n",
    "    if show:\n",
    "        cv2.imshow('Model View', np.array(img)[:,:,[2,1,0]]) # if the user wants to see the model view, rearrange the channels and show the image\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): # The wait insures the image is shown, and the other portion of the command allows the user to stop the program by pressing 'q'\n",
    "            cv2.destroyAllWindows() # destroy the image window\n",
    "            break # step out of the loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e531c17a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "98fdb8f8465a6abd790453bf04bfe1a102bc321501e41cb4e89b4f638decdf36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
