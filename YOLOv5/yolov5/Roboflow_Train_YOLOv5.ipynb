{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of Roboflow-Train-YOLOv5",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "#Install Dependencies\n",
    "\n",
    "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wbvMlHd_QwMG"
   },
   "source": [
    "from IPython.display import Image, clear_output  # to display images"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9nmZZnWOgJ2S",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "74669f8c-4f9d-4012-9785-0f497deb0494"
   },
   "source": [
    "# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n",
    "# use the best weights!\n",
    "%cd /content/yolov5/\n",
    "!python detect.py --weights Yolov5Halo.pt --img 416 --conf 0.5 --source C:\\Users\\blain\\Documents\\Git\\AutoAim\\halo_data"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/yolov5\n",
      "\u001B[34m\u001B[1mdetect: \u001B[0mweights=['runs/train/yolov5s_results/weights/best.pt'], source=../test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v6.1-135-g7926afc torch 1.10.0+cu111 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/1 /content/test/images/2022-01-31 14_36_09.498686-screenshot-54.png: 416x416 1 enemy, Done. (0.014s)\n",
      "Speed: 0.4ms pre-process, 13.6ms inference, 1.4ms NMS per image at shape (1, 3, 416, 416)\n",
      "Results saved to \u001B[1mruns/detect/exp3\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "odKEqYtTgbRc"
   },
   "source": [
    "#display inference on ALL test images\n",
    "#this looks much better with longer training above\n",
    "\n",
    "import glob\n",
    "from IPython.display import Image, display\n",
    "\n",
    "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.png'): #assuming JPG\n",
    "    display(Image(filename=imageName))\n",
    "    print(\"\\n\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uPq9mVgiBql"
   },
   "source": [
    "# Export Trained Weights for Future Inference\n",
    "\n",
    "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVpCFeU-K4gb"
   },
   "source": [
    "## Congrats!\n",
    "\n",
    "Hope you enjoyed this!\n",
    "\n",
    "--Team [Roboflow](https://roboflow.ai)"
   ]
  }
 ]
}