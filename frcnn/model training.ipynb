{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f669dbdb-d9c0-49f5-bff3-ec29f8e055dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "from dataset import get_transforms, FiftyOneTorchDataset, collate_fn\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.lib.display.IFrame at 0x19b06d44cd0>",
      "text/html": "\n        <iframe\n            width=\"100%\"\n            height=\"800\"\n            src=\"http://localhost:5151/?notebook=true&handleId=f2eea1ad-9e44-4453-8e05-2be12ff03859\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 5\n",
    "num_epochs = 30\n",
    "TRAIN_TEST_SPLIT = .9\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "TRAINED_MODEL_FILENAME = \"model/halo_FRCNN_model.pth\"\n",
    "\n",
    "# re load the dataset\n",
    "if len(fo.list_datasets()) > 0:\n",
    "    dataset = fo.load_dataset(\"halo-dataset\")\n",
    "else:\n",
    "    name = \"halo-dataset\"\n",
    "    data_path = \"C:/Users/blain\\Documents\\Git\\AutoAim/halo_data/\"\n",
    "    labels_path = \"C:/Users/blain\\Documents\\Git\\AutoAim/halo_data/labels/\"\n",
    "\n",
    "    classes = [\"enemy\"]\n",
    "\n",
    "    # Import dataset by explicitly providing paths to the source media and labels\n",
    "    dataset = fo.Dataset.from_dir(\n",
    "        dataset_type=fo.types.YOLOv4Dataset,\n",
    "        data_path=data_path,\n",
    "        labels_path=labels_path,\n",
    "        classes=classes,\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "dataset.compute_metadata()\n",
    "session = fo.launch_app(dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning on 45 samples\n",
      "Testing on 5 samples\n"
     ]
    }
   ],
   "source": [
    "train_transforms = get_transforms(train=True)\n",
    "test_transforms = get_transforms(train=False)\n",
    "\n",
    "# split the dataset in train and test set\n",
    "train_view = dataset.take((len(dataset) * TRAIN_TEST_SPLIT), seed=51)\n",
    "test_view = dataset.exclude([s.id for s in train_view])\n",
    "\n",
    "print(f'Traning on {len(train_view)} samples')\n",
    "print(f'Testing on {len(test_view)} samples')\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "train_dataset = FiftyOneTorchDataset(train_view, train_transforms,)\n",
    "evaluation_dataset = FiftyOneTorchDataset(test_view, test_transforms)\n",
    "\n",
    "#session.view = train_view"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    evaluation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# load a pre-trained pre-trained FRCNN from torch\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one using our one enemy class.  Use 2 here because we need a background class\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n",
    "\n",
    "# send the model to the training device\n",
    "model.to(DEVICE)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by\n",
    "# 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5637a35-e60e-4210-9876-18209fa57380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [0/9]  eta: 0:00:35  lr: 0.000629  loss: 0.7192 (0.7192)  loss_classifier: 0.5892 (0.5892)  loss_box_reg: 0.1035 (0.1035)  loss_objectness: 0.0246 (0.0246)  loss_rpn_box_reg: 0.0019 (0.0019)  time: 3.9783  data: 0.0950  max mem: 3465\n",
      "Epoch: [0]  [1/9]  eta: 0:00:18  lr: 0.001254  loss: 0.6875 (0.7034)  loss_classifier: 0.5715 (0.5804)  loss_box_reg: 0.0573 (0.0804)  loss_objectness: 0.0246 (0.0336)  loss_rpn_box_reg: 0.0019 (0.0090)  time: 2.2717  data: 0.0915  max mem: 3789\n",
      "Epoch: [0]  [2/9]  eta: 0:00:11  lr: 0.001878  loss: 0.6875 (0.6603)  loss_classifier: 0.5715 (0.5405)  loss_box_reg: 0.0884 (0.0831)  loss_objectness: 0.0246 (0.0295)  loss_rpn_box_reg: 0.0037 (0.0072)  time: 1.6928  data: 0.0870  max mem: 3789\n",
      "Epoch: [0]  [3/9]  eta: 0:00:08  lr: 0.002503  loss: 0.5742 (0.5979)  loss_classifier: 0.4608 (0.4644)  loss_box_reg: 0.0884 (0.0862)  loss_objectness: 0.0246 (0.0380)  loss_rpn_box_reg: 0.0037 (0.0093)  time: 1.4033  data: 0.0838  max mem: 3789\n",
      "Epoch: [0]  [4/9]  eta: 0:00:06  lr: 0.003127  loss: 0.5742 (0.5191)  loss_classifier: 0.4608 (0.3900)  loss_box_reg: 0.0884 (0.0857)  loss_objectness: 0.0246 (0.0344)  loss_rpn_box_reg: 0.0079 (0.0090)  time: 1.2301  data: 0.0830  max mem: 3789\n",
      "Epoch: [0]  [5/9]  eta: 0:00:04  lr: 0.003751  loss: 0.4107 (0.4723)  loss_classifier: 0.2362 (0.3437)  loss_box_reg: 0.0884 (0.0905)  loss_objectness: 0.0213 (0.0300)  loss_rpn_box_reg: 0.0037 (0.0081)  time: 1.1149  data: 0.0822  max mem: 3789\n",
      "Epoch: [0]  [6/9]  eta: 0:00:03  lr: 0.004376  loss: 0.4107 (0.4327)  loss_classifier: 0.2362 (0.3117)  loss_box_reg: 0.0884 (0.0876)  loss_objectness: 0.0213 (0.0261)  loss_rpn_box_reg: 0.0037 (0.0073)  time: 1.0330  data: 0.0817  max mem: 3789\n",
      "Epoch: [0]  [7/9]  eta: 0:00:01  lr: 0.005000  loss: 0.3498 (0.4224)  loss_classifier: 0.2204 (0.3003)  loss_box_reg: 0.0884 (0.0912)  loss_objectness: 0.0200 (0.0241)  loss_rpn_box_reg: 0.0034 (0.0067)  time: 0.9708  data: 0.0814  max mem: 3789\n",
      "Epoch: [0]  [8/9]  eta: 0:00:00  lr: 0.005000  loss: 0.3735 (0.4169)  loss_classifier: 0.2362 (0.2941)  loss_box_reg: 0.0954 (0.0931)  loss_objectness: 0.0200 (0.0235)  loss_rpn_box_reg: 0.0034 (0.0063)  time: 0.9228  data: 0.0813  max mem: 3789\n",
      "Epoch: [0] Total time: 0:00:08 (0.9233 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/9]  eta: 0:00:02  model_time: 0.2300 (0.2300)  evaluator_time: 0.0010 (0.0010)  time: 0.3120  data: 0.0770  max mem: 3789\n",
      "Test:  [8/9]  eta: 0:00:00  model_time: 0.2170 (0.2198)  evaluator_time: 0.0010 (0.0010)  time: 0.3034  data: 0.0786  max mem: 3789\n",
      "Test: Total time: 0:00:02 (0.3034 s / it)\n",
      "Averaged stats: model_time: 0.2170 (0.2198)  evaluator_time: 0.0010 (0.0010)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Epoch: [1]  [0/9]  eta: 0:00:05  lr: 0.005000  loss: 0.3737 (0.3737)  loss_classifier: 0.2436 (0.2436)  loss_box_reg: 0.1222 (0.1222)  loss_objectness: 0.0074 (0.0074)  loss_rpn_box_reg: 0.0006 (0.0006)  time: 0.5730  data: 0.0790  max mem: 3789\n",
      "Epoch: [1]  [1/9]  eta: 0:00:04  lr: 0.005000  loss: 0.3417 (0.3577)  loss_classifier: 0.2154 (0.2295)  loss_box_reg: 0.1169 (0.1195)  loss_objectness: 0.0063 (0.0068)  loss_rpn_box_reg: 0.0006 (0.0018)  time: 0.5575  data: 0.0805  max mem: 3789\n",
      "Epoch: [1]  [2/9]  eta: 0:00:03  lr: 0.005000  loss: 0.3737 (0.3988)  loss_classifier: 0.2436 (0.2467)  loss_box_reg: 0.1222 (0.1429)  loss_objectness: 0.0074 (0.0070)  loss_rpn_box_reg: 0.0028 (0.0022)  time: 0.5537  data: 0.0797  max mem: 3789\n",
      "Epoch: [1]  [3/9]  eta: 0:00:03  lr: 0.005000  loss: 0.3417 (0.3638)  loss_classifier: 0.2154 (0.2209)  loss_box_reg: 0.1169 (0.1299)  loss_objectness: 0.0074 (0.0084)  loss_rpn_box_reg: 0.0028 (0.0047)  time: 0.5722  data: 0.0935  max mem: 3789\n",
      "Epoch: [1]  [4/9]  eta: 0:00:02  lr: 0.005000  loss: 0.3720 (0.3655)  loss_classifier: 0.2154 (0.2163)  loss_box_reg: 0.1222 (0.1342)  loss_objectness: 0.0075 (0.0106)  loss_rpn_box_reg: 0.0031 (0.0044)  time: 0.5666  data: 0.0912  max mem: 3789\n",
      "Epoch: [1]  [5/9]  eta: 0:00:02  lr: 0.005000  loss: 0.3417 (0.3400)  loss_classifier: 0.1980 (0.1947)  loss_box_reg: 0.1169 (0.1291)  loss_objectness: 0.0075 (0.0105)  loss_rpn_box_reg: 0.0031 (0.0057)  time: 0.5690  data: 0.0892  max mem: 3789\n",
      "Epoch: [1]  [6/9]  eta: 0:00:01  lr: 0.005000  loss: 0.3417 (0.3211)  loss_classifier: 0.1980 (0.1781)  loss_box_reg: 0.1169 (0.1266)  loss_objectness: 0.0102 (0.0110)  loss_rpn_box_reg: 0.0031 (0.0054)  time: 0.5659  data: 0.0880  max mem: 3789\n",
      "Epoch: [1]  [7/9]  eta: 0:00:01  lr: 0.005000  loss: 0.2591 (0.3105)  loss_classifier: 0.1436 (0.1676)  loss_box_reg: 0.1169 (0.1269)  loss_objectness: 0.0102 (0.0111)  loss_rpn_box_reg: 0.0031 (0.0049)  time: 0.5671  data: 0.0915  max mem: 3789\n",
      "Epoch: [1]  [8/9]  eta: 0:00:00  lr: 0.005000  loss: 0.2591 (0.2912)  loss_classifier: 0.1436 (0.1538)  loss_box_reg: 0.1169 (0.1201)  loss_objectness: 0.0104 (0.0110)  loss_rpn_box_reg: 0.0031 (0.0064)  time: 0.5637  data: 0.0901  max mem: 3789\n",
      "Epoch: [1] Total time: 0:00:05 (0.5641 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "Test:  [0/9]  eta: 0:00:02  model_time: 0.2190 (0.2190)  evaluator_time: 0.0040 (0.0040)  time: 0.3050  data: 0.0780  max mem: 3789\n",
      "Test:  [8/9]  eta: 0:00:00  model_time: 0.2270 (0.2297)  evaluator_time: 0.0050 (0.0050)  time: 0.3233  data: 0.0847  max mem: 3789\n",
      "Test: Total time: 0:00:02 (0.3236 s / it)\n",
      "Averaged stats: model_time: 0.2270 (0.2297)  evaluator_time: 0.0050 (0.0050)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.690\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.253\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.469\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.398\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.477\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.492\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.333\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.623\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n",
      "Epoch: [2]  [0/9]  eta: 0:00:05  lr: 0.005000  loss: 0.2392 (0.2392)  loss_classifier: 0.0737 (0.0737)  loss_box_reg: 0.1504 (0.1504)  loss_objectness: 0.0137 (0.0137)  loss_rpn_box_reg: 0.0013 (0.0013)  time: 0.5630  data: 0.0920  max mem: 3789\n",
      "Epoch: [2]  [1/9]  eta: 0:00:04  lr: 0.005000  loss: 0.2075 (0.2233)  loss_classifier: 0.0588 (0.0663)  loss_box_reg: 0.1269 (0.1387)  loss_objectness: 0.0137 (0.0145)  loss_rpn_box_reg: 0.0013 (0.0039)  time: 0.5640  data: 0.0880  max mem: 3789\n",
      "Epoch: [2]  [2/9]  eta: 0:00:04  lr: 0.005000  loss: 0.2232 (0.2233)  loss_classifier: 0.0727 (0.0684)  loss_box_reg: 0.1288 (0.1354)  loss_objectness: 0.0137 (0.0129)  loss_rpn_box_reg: 0.0065 (0.0066)  time: 0.5727  data: 0.0873  max mem: 3789\n",
      "Epoch: [2]  [3/9]  eta: 0:00:03  lr: 0.005000  loss: 0.2075 (0.2113)  loss_classifier: 0.0588 (0.0623)  loss_box_reg: 0.1269 (0.1272)  loss_objectness: 0.0137 (0.0133)  loss_rpn_box_reg: 0.0065 (0.0085)  time: 0.5881  data: 0.0947  max mem: 3789\n",
      "Epoch: [2]  [4/9]  eta: 0:00:02  lr: 0.005000  loss: 0.2232 (0.2155)  loss_classifier: 0.0727 (0.0651)  loss_box_reg: 0.1288 (0.1305)  loss_objectness: 0.0137 (0.0116)  loss_rpn_box_reg: 0.0072 (0.0082)  time: 0.5861  data: 0.0956  max mem: 3789\n",
      "Epoch: [2]  [5/9]  eta: 0:00:02  lr: 0.005000  loss: 0.2075 (0.2074)  loss_classifier: 0.0588 (0.0635)  loss_box_reg: 0.1269 (0.1258)  loss_objectness: 0.0096 (0.0111)  loss_rpn_box_reg: 0.0065 (0.0071)  time: 0.5791  data: 0.0932  max mem: 3789\n",
      "Epoch: [2]  [6/9]  eta: 0:00:01  lr: 0.005000  loss: 0.2211 (0.2094)  loss_classifier: 0.0588 (0.0619)  loss_box_reg: 0.1288 (0.1313)  loss_objectness: 0.0096 (0.0099)  loss_rpn_box_reg: 0.0065 (0.0064)  time: 0.5766  data: 0.0916  max mem: 3789\n",
      "Epoch: [2]  [7/9]  eta: 0:00:01  lr: 0.005000  loss: 0.2075 (0.1981)  loss_classifier: 0.0556 (0.0590)  loss_box_reg: 0.1269 (0.1236)  loss_objectness: 0.0083 (0.0090)  loss_rpn_box_reg: 0.0065 (0.0064)  time: 0.5716  data: 0.0902  max mem: 3789\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# training for one epoch\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m     \u001B[43mengine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_data_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43mscaler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscaler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprint_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# update the learning rate\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     lr_scheduler\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\Documents\\Git\\AutoAim\\frcnn\\engine.py:31\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(model, optimizer, data_loader, device, epoch, print_freq, scaler)\u001B[0m\n\u001B[0;32m     29\u001B[0m targets \u001B[38;5;241m=\u001B[39m [{k: v\u001B[38;5;241m.\u001B[39mto(device) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m t\u001B[38;5;241m.\u001B[39mitems()} \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m targets]\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(enabled\u001B[38;5;241m=\u001B[39mscaler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m---> 31\u001B[0m     loss_dict \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m     losses \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(loss \u001B[38;5;28;01mfor\u001B[39;00m loss \u001B[38;5;129;01min\u001B[39;00m loss_dict\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# reduce losses over all GPUs for logging purposes\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py:95\u001B[0m, in \u001B[0;36mGeneralizedRCNN.forward\u001B[1;34m(self, images, targets)\u001B[0m\n\u001B[0;32m     89\u001B[0m             degen_bb: List[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m boxes[bb_idx]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m     90\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     91\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll bounding boxes should have positive height and width.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     92\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Found invalid box \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdegen_bb\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for target at index \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget_idx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     93\u001B[0m             )\n\u001B[1;32m---> 95\u001B[0m features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackbone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(features, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m     97\u001B[0m     features \u001B[38;5;241m=\u001B[39m OrderedDict([(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m, features)])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\detection\\backbone_utils.py:53\u001B[0m, in \u001B[0;36mBackboneWithFPN.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Tensor]:\n\u001B[1;32m---> 53\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfpn(x)\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\_utils.py:63\u001B[0m, in \u001B[0;36mIntermediateLayerGetter.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     61\u001B[0m out \u001B[38;5;241m=\u001B[39m OrderedDict()\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m---> 63\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_layers:\n\u001B[0;32m     65\u001B[0m         out_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_layers[name]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 141\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\models\\resnet.py:153\u001B[0m, in \u001B[0;36mBottleneck.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    150\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[0;32m    152\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv3(out)\n\u001B[1;32m--> 153\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbn3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsample \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    156\u001B[0m     identity \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownsample(x)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torchvision\\ops\\misc.py:61\u001B[0m, in \u001B[0;36mFrozenBatchNorm2d.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     59\u001B[0m rm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrunning_mean\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     60\u001B[0m scale \u001B[38;5;241m=\u001B[39m w \u001B[38;5;241m*\u001B[39m (rv \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meps)\u001B[38;5;241m.\u001B[39mrsqrt()\n\u001B[1;32m---> 61\u001B[0m bias \u001B[38;5;241m=\u001B[39m \u001B[43mb\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mrm\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mscale\u001B[49m\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x \u001B[38;5;241m*\u001B[39m scale \u001B[38;5;241m+\u001B[39m bias\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # training for one epoch\n",
    "    engine.train_one_epoch(model, optimizer, train_data_loader, DEVICE, epoch,scaler=scaler, print_freq=1)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    engine.evaluate(model, train_data_loader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def apply_nms(orig_prediction, iou_thresh=0.3):\n",
    "\n",
    "    # torchvision returns the indices of the bboxes to keep\n",
    "    keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n",
    "\n",
    "    final_prediction = orig_prediction\n",
    "    final_prediction['boxes'] = final_prediction['boxes'][keep]\n",
    "    final_prediction['scores'] = final_prediction['scores'][keep]\n",
    "    final_prediction['labels'] = final_prediction['labels'][keep]\n",
    "\n",
    "    return final_prediction\n",
    "\n",
    "# function to convert a torchtensor back to PIL image\n",
    "def torch_to_pil(img):\n",
    "    return torchvision.transforms.ToPILImage()(img).convert('RGB')\n",
    "\n",
    "import tkinter\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def plot_img_bbox(img, target):\n",
    "    # plot the image and bboxes\n",
    "    # Bounding boxes are defined as follows: x-min y-min width height\n",
    "    fig, a = plt.subplots(1,1)\n",
    "    fig.set_size_inches(5,5)\n",
    "    a.imshow(img)\n",
    "    for box in (target['boxes']):\n",
    "        x, y, width, height  = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
    "        rect = patches.Rectangle((x, y),\n",
    "                                 width, height,\n",
    "                                 linewidth = 2,\n",
    "                                 edgecolor = 'r',\n",
    "                                 facecolor = 'none')\n",
    "\n",
    "        # Draw the bounding box on top of the image\n",
    "        a.add_patch(rect)\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "051b74da-ac68-4cbf-b70f-4e1c45c3e3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted #boxes:  20\n",
      "real #boxes:  1\n"
     ]
    }
   ],
   "source": [
    "# pick one image from the test set\n",
    "img, target = train_dataset[5]\n",
    "# put the model in evaluation mode\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model([img.to(DEVICE)])[0]\n",
    "\n",
    "print('predicted #boxes: ', len(prediction['labels']))\n",
    "print('real #boxes: ', len(target['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPECTED OUTPUT\n"
     ]
    }
   ],
   "source": [
    "print('EXPECTED OUTPUT')\n",
    "plot_img_bbox(torch_to_pil(img), target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted OUTPUT\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredicted OUTPUT\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mplot_img_bbox\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch_to_pil\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36mplot_img_bbox\u001B[1;34m(img, target)\u001B[0m\n\u001B[0;32m     31\u001B[0m     rect \u001B[38;5;241m=\u001B[39m patches\u001B[38;5;241m.\u001B[39mRectangle((x, y),\n\u001B[0;32m     32\u001B[0m                              width, height,\n\u001B[0;32m     33\u001B[0m                              linewidth \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m     34\u001B[0m                              edgecolor \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     35\u001B[0m                              facecolor \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;66;03m# Draw the bounding box on top of the image\u001B[39;00m\n\u001B[1;32m---> 38\u001B[0m     \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_patch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrect\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     39\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\matplotlib\\axes\\_base.py:2358\u001B[0m, in \u001B[0;36m_AxesBase.add_patch\u001B[1;34m(self, p)\u001B[0m\n\u001B[0;32m   2356\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m p\u001B[38;5;241m.\u001B[39mget_clip_path() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2357\u001B[0m     p\u001B[38;5;241m.\u001B[39mset_clip_path(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch)\n\u001B[1;32m-> 2358\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_patch_limits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2359\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_children\u001B[38;5;241m.\u001B[39mappend(p)\n\u001B[0;32m   2360\u001B[0m p\u001B[38;5;241m.\u001B[39m_remove_method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_children\u001B[38;5;241m.\u001B[39mremove\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\matplotlib\\axes\\_base.py:2381\u001B[0m, in \u001B[0;36m_AxesBase._update_patch_limits\u001B[1;34m(self, patch)\u001B[0m\n\u001B[0;32m   2379\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m vertices\u001B[38;5;241m.\u001B[39msize:\n\u001B[0;32m   2380\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m-> 2381\u001B[0m patch_trf \u001B[38;5;241m=\u001B[39m \u001B[43mpatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2382\u001B[0m updatex, updatey \u001B[38;5;241m=\u001B[39m patch_trf\u001B[38;5;241m.\u001B[39mcontains_branch_seperately(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransData)\n\u001B[0;32m   2383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (updatex \u001B[38;5;129;01mor\u001B[39;00m updatey):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\matplotlib\\patches.py:278\u001B[0m, in \u001B[0;36mPatch.get_transform\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    276\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    277\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the `~.transforms.Transform` applied to the `Patch`.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 278\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_patch_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m artist\u001B[38;5;241m.\u001B[39mArtist\u001B[38;5;241m.\u001B[39mget_transform(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\matplotlib\\patches.py:752\u001B[0m, in \u001B[0;36mRectangle.get_patch_transform\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_patch_transform\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;66;03m# Note: This cannot be called until after this has been added to\u001B[39;00m\n\u001B[0;32m    749\u001B[0m     \u001B[38;5;66;03m# an Axes, otherwise unit conversion will fail. This makes it very\u001B[39;00m\n\u001B[0;32m    750\u001B[0m     \u001B[38;5;66;03m# important to call the accessor method and not directly access the\u001B[39;00m\n\u001B[0;32m    751\u001B[0m     \u001B[38;5;66;03m# transformation member variable.\u001B[39;00m\n\u001B[1;32m--> 752\u001B[0m     bbox \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_bbox\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    753\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (transforms\u001B[38;5;241m.\u001B[39mBboxTransformTo(bbox)\n\u001B[0;32m    754\u001B[0m             \u001B[38;5;241m+\u001B[39m transforms\u001B[38;5;241m.\u001B[39mAffine2D()\u001B[38;5;241m.\u001B[39mrotate_deg_around(\n\u001B[0;32m    755\u001B[0m                 bbox\u001B[38;5;241m.\u001B[39mx0, bbox\u001B[38;5;241m.\u001B[39my0, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mangle))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\matplotlib\\patches.py:845\u001B[0m, in \u001B[0;36mRectangle.get_bbox\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    843\u001B[0m \u001B[38;5;124;03m\"\"\"Return the `.Bbox`.\"\"\"\u001B[39;00m\n\u001B[0;32m    844\u001B[0m x0, y0, x1, y1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_units()\n\u001B[1;32m--> 845\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBbox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_extents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my1\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\matplotlib\\transforms.py:839\u001B[0m, in \u001B[0;36mBbox.from_extents\u001B[1;34m(minpos, *args)\u001B[0m\n\u001B[0;32m    822\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    823\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_extents\u001B[39m(\u001B[38;5;241m*\u001B[39margs, minpos\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    825\u001B[0m \u001B[38;5;124;03m    Create a new Bbox from *left*, *bottom*, *right* and *top*.\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    837\u001B[0m \u001B[38;5;124;03m       scales where negative bounds result in floating point errors.\u001B[39;00m\n\u001B[0;32m    838\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 839\u001B[0m     bbox \u001B[38;5;241m=\u001B[39m Bbox(\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    840\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m minpos \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    841\u001B[0m         bbox\u001B[38;5;241m.\u001B[39m_minpos[:] \u001B[38;5;241m=\u001B[39m minpos\n",
      "File \u001B[1;32m<__array_function__ internals>:180\u001B[0m, in \u001B[0;36mreshape\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001B[0m, in \u001B[0;36mreshape\u001B[1;34m(a, newshape, order)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_reshape_dispatcher)\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreshape\u001B[39m(a, newshape, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    200\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    201\u001B[0m \u001B[38;5;124;03m    Gives a new shape to an array without changing its data.\u001B[39;00m\n\u001B[0;32m    202\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    296\u001B[0m \u001B[38;5;124;03m           [5, 6]])\u001B[39;00m\n\u001B[0;32m    297\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mreshape\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnewshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001B[0m, in \u001B[0;36m_wrapfunc\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     52\u001B[0m bound \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, method, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bound \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _wrapit(obj, method, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m bound(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001B[0m, in \u001B[0;36m_wrapit\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[0;32m     42\u001B[0m     wrap \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 43\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m, method)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m wrap:\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, mu\u001B[38;5;241m.\u001B[39mndarray):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch-frcnn\\lib\\site-packages\\torch\\_tensor.py:732\u001B[0m, in \u001B[0;36mTensor.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m    730\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m__array__, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 732\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    733\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mTypeError\u001B[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "print('Predicted OUTPUT')\n",
    "plot_img_bbox(torch_to_pil(img), prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'boxes': tensor([[309.7555, 301.3320, 341.0692, 365.7558],\n         [317.3797, 283.0357, 347.8021, 364.2500],\n         [313.7378, 309.4354, 343.2237, 345.4171],\n         [320.9241, 289.2632, 335.9792, 376.0393],\n         [300.5381, 276.0068, 346.6392, 385.0882],\n         [324.9810, 308.6666, 345.9605, 363.0152],\n         [295.9156, 291.6388, 332.5501, 369.7255],\n         [303.7346, 322.2299, 342.6017, 349.5093],\n         [319.3935, 296.0606, 354.1078, 394.8098],\n         [299.9713, 313.4511, 331.4622, 355.6393],\n         [314.3451, 294.9984, 345.9138, 335.1835],\n         [297.6116, 323.2365, 339.1385, 372.4258],\n         [323.8223, 279.0023, 338.0670, 346.9181],\n         [319.9921, 310.4760, 351.0009, 336.2351],\n         [300.5486, 313.3826, 362.5050, 351.1314],\n         [310.0913, 314.7109, 332.8177, 341.9038],\n         [313.2756, 328.1349, 343.6857, 355.2656],\n         [318.8855, 315.9940, 361.6632, 370.5016],\n         [313.4791, 279.4824, 363.4555, 416.7647],\n         [263.4851, 287.8560, 347.5216, 377.8318]], device='cuda:0'),\n 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        device='cuda:0'),\n 'scores': tensor([0.7498, 0.7124, 0.5286, 0.4951, 0.4933, 0.3395, 0.2952, 0.2801, 0.2272,\n         0.1958, 0.1632, 0.1575, 0.1486, 0.1288, 0.1287, 0.1275, 0.1032, 0.0827,\n         0.0761, 0.0676], device='cuda:0')}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m cpu_pred \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m prediction:\n\u001B[0;32m      3\u001B[0m     cpu_pred[key] \u001B[38;5;241m=\u001B[39m value\u001B[38;5;241m.\u001B[39mcpu()\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "cpu_pred = {}\n",
    "for key, value in prediction:\n",
    "    cpu_pred[key] = value.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "torch-frcnn",
   "language": "python",
   "display_name": "torch-frcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}